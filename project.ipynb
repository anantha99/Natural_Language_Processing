{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Ananthapadmanabha\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.fileids())\n",
    "movie_reviews.fileids() # to get all the files present in the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['films', 'adapted', 'from', 'comic', 'books', 'have', ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to access all the words present in the file \n",
    "movie_reviews.words(movie_reviews.fileids('pos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'happy', 'bastard', \"'\", 's', 'quick', 'movie', ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.words(movie_reviews.fileids()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is stemming and lemmatization?\n",
    "\n",
    "Stemming: The process of reducing the words to their stem. Its basically converting all the words into their nearest meaning root word which will help us in doing analysis.\n",
    "Using the stem word we will be able to determine wheather a word is positive or negative.\n",
    "Application: detecting spam words\n",
    "Lemmatization : Same as stemming but the stem will have meaning that can be understood by a human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...], 'neg'), (['the', 'happy', 'bastard', \"'\", 's', 'quick', 'movie', ...], 'neg'), (['it', 'is', 'movies', 'like', 'these', 'that', 'make', ...], 'neg'), (['\"', 'quest', 'for', 'camelot', '\"', 'is', 'warner', ...], 'neg')]\n"
     ]
    }
   ],
   "source": [
    "# to append all the words present in the files to a document \n",
    "document = []\n",
    "for category in movie_reviews.categories():\n",
    "    for files in movie_reviews.fileids(category):\n",
    "        document.append((movie_reviews.words(files),category))\n",
    "print(document[0:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets shuffle the documents because we will have a mix of positive and negative documents\n",
    "import random\n",
    "random.shuffle(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['in', 'the', 'grand', 'scheme', 'of', 'mel', 'gibson', ...], 'pos'), (['this', 'film', 'is', 'worth', 'seeing', 'for', ...], 'neg'), (['i', 'guess', 'there', 'are', 'those', 'who', 'have', ...], 'pos'), (['for', 'timing', 'reasons', 'having', 'to', 'do', ...], 'neg')]\n"
     ]
    }
   ],
   "source": [
    "print(document[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove the stopwords and apply lemmatization and to get the part of speech of each of the words that the data belongs to\n",
    "def clean_code(words):\n",
    "    output_words = []\n",
    "    for word in words:\n",
    "        if word.lower() not in stops:\n",
    "            pos = pos_tag(word)\n",
    "            clean_word = lemmatizer.lemmatize(word, pos=pos[0][1])\n",
    "            output_words.append(clean_word.lower())\n",
    "    return output_words\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the pos_tag \n",
    "#note: the input to this pos tag shouls always be an array []\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enemy', 'NN')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of getting pos tag for a word \n",
    "word = \"enemy\"\n",
    "pos_tag([word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing a lemmatizer \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dfac027262927982790583fc11aace72addb35d60841fa2981b59a23fc0f5c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
